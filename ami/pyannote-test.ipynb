{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont forget to accept license terms at https://huggingface.co/pyannote/speaker-diarization\n",
    "# and at https://huggingface.co/pyannote/segmentation\n",
    "# and at https://huggingface.co/pyannote/speaker-diarization-3.1\n",
    "# and at https://huggingface.co/pyannote/segmentation-3.0\n",
    "import os\n",
    "\n",
    "hugging_face_token = str(os.getenv('HF_TOKEN'))\n",
    "#print(hugging_face_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install pyannote\n",
    "!pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechbrain in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: hyperpyyaml in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (1.3.2)\n",
      "Requirement already satisfied: numpy in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (1.23.5)\n",
      "Requirement already satisfied: packaging in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (23.1)\n",
      "Requirement already satisfied: scipy in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (1.10.1)\n",
      "Requirement already satisfied: sentencepiece in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.9 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (2.3.0)\n",
      "Requirement already satisfied: torchaudio in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from speechbrain) (0.17.2)\n",
      "Requirement already satisfied: filelock in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (4.12.0)\n",
      "Requirement already satisfied: sympy in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from torch>=1.9->speechbrain) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->speechbrain) (12.5.40)\n",
      "Requirement already satisfied: requests in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from hyperpyyaml->speechbrain) (0.17.32)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from jinja2->torch>=1.9->speechbrain) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->huggingface-hub->speechbrain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->huggingface-hub->speechbrain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->huggingface-hub->speechbrain) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# to install speechbrain\n",
    "!pip install speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535775e23f1744eeb153172d1b7c5aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60522724e640434c89f8081cdf8b25bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde938cdc57742fa9951b78e386dfe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccc4a9c567c413d82256d87a9b991ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# diarization\n",
    "# reference (with results on AMI) https://github.com/pyannote/pyannote-audio?tab=readme-ov-file\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "import speechbrain\n",
    "\n",
    "# \"pyannote/speaker-diarization@2.1\"\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
    "                                    use_auth_token=hugging_face_token)\n",
    "print(1)\n",
    "audio_input = '/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/audio/Array1-01/EN2002a.Array1-01.wav'\n",
    "# apply the pipeline to an audio file\n",
    "diarization = pipeline(audio_input, num_speakers = 4)\n",
    "print(2)\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"/home/kozi/Documents/_onlab_git/ami/audio-test-pyannote.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TextIO, Optional, Iterator, Text\n",
    "\n",
    "class Annotation(Annotation):\n",
    "    @classmethod\n",
    "    def from_rttm(\n",
    "        cls, rttm_file: TextIO, uri: Optional[str] = None, modality: Optional[str] = None,\n",
    "    ) -> \"Annotation\":\n",
    "        \"\"\"Create annotation from rttmParameters\n",
    "        ----------\n",
    "        rttm_file : string,\n",
    "            path to the rttm file\n",
    "        uri : string, optional\n",
    "            name of annotated resource (e.g. audio or video file)\n",
    "        modality : string, optional\n",
    "            name of annotated modality\n",
    "        Returns\n",
    "        -------\n",
    "        annotation : Annotation\n",
    "            New annotation\n",
    "        \"\"\"\n",
    "        segment_list = []\n",
    "        for line in rttm_file:\n",
    "            line = line.rstrip().split(\" \")\n",
    "            segment_list.append(\n",
    "                (\n",
    "                    Segment(start=float(line[3]), end=float(line[3]) + float(line[4])),\n",
    "                    int(line[2]),\n",
    "                    str(line[7]),\n",
    "                )\n",
    "            )\n",
    "        return Annotation.from_records(segment_list, uri, modality)\n",
    "    def _iter_audacity(self) -> Iterator[Text]:\n",
    "        \"\"\"Generate lines for a audacity marker file for this annotation\n",
    "        Returns\n",
    "        -------\n",
    "        iterator: Iterator[str]\n",
    "            An iterator over audacity text lines\n",
    "        \"\"\"\n",
    "        for segment, _, label in self.itertracks(yield_label=True):\n",
    "            yield f\"{segment.start:.3f}\\t{segment.start + segment.duration:.3f}\\t{label}\\n\"\n",
    "    def to_audacity(self) -> Text:\n",
    "        \"\"\"Serialize annotation as a string using Audacity format\n",
    "        Returns\n",
    "        -------\n",
    "        serialized: str\n",
    "            audacity marker string\n",
    "        \"\"\"\n",
    "        return \"\".join([line for line in self._iter_audacity()])\n",
    "    def write_audacity(self, file: TextIO):\n",
    "        \"\"\"Dump annotation to file using Audacity format\n",
    "        Parameters\n",
    "        ----------\n",
    "        file : file object\n",
    "        Usage\n",
    "        -----\n",
    "        >>> with open('file.txt', 'w') as file:\n",
    "        ...     annotation.write_audacity(file)\n",
    "        \"\"\"\n",
    "        for line in self._iter_audacity():\n",
    "            file.write(line)\n",
    "    @classmethod\n",
    "    def from_audacity(\n",
    "        cls, audacity_file: str, uri: Optional[str] = None, modality: Optional[str] = None,\n",
    "    ) -> \"Annotation\":\n",
    "        \"\"\"Create annotation from rttm file\n",
    "        Parameters\n",
    "        ----------\n",
    "        audacity_txt_file : string,\n",
    "            path to the rttm file\n",
    "        uri : string, optional\n",
    "            name of annotated resource (e.g. audio or video file)\n",
    "        modality : string, optional\n",
    "            name of annotated modality\n",
    "        Returns\n",
    "        -------\n",
    "        annotation : Annotation\n",
    "            New annotation\n",
    "        \"\"\"\n",
    "        segment_list = []\n",
    "        for line in audacity_file:\n",
    "            start, end, label = line.rstrip().split(\"\\t\")\n",
    "            segment_list.append(\n",
    "                (Segment(start=float(start), end=float(end)), 1, str(label))\n",
    "            )\n",
    "        return Annotation.from_records(segment_list, uri, modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyannote\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiarization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiarizationErrorRate\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f :\n\u001b[0;32m----> 5\u001b[0m     ref \u001b[38;5;241m=\u001b[39m \u001b[43mAnnotation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_audacity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/kozi/Documents/_onlab_git/ami/audio-test-pyannote.rttm\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f :\n\u001b[1;32m      7\u001b[0m     hyp \u001b[38;5;241m=\u001b[39m Annotation\u001b[38;5;241m.\u001b[39mfrom_rttm(f)\n",
      "Cell \u001b[0;32mIn[21], line 81\u001b[0m, in \u001b[0;36mAnnotation.from_audacity\u001b[0;34m(cls, audacity_file, uri, modality)\u001b[0m\n\u001b[1;32m     79\u001b[0m segment_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m audacity_file:\n\u001b[0;32m---> 81\u001b[0m     start, end, label \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     segment_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     83\u001b[0m         (Segment(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(start), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(end)), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mstr\u001b[39m(label))\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Annotation\u001b[38;5;241m.\u001b[39mfrom_records(segment_list, uri, modality)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "# okay this tutorial and file is unusable\n",
    "# calculate DER metrics\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "\n",
    "with open('/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm') as f :\n",
    "    ref = Annotation.from_audacity(f)\n",
    "with open('/home/kozi/Documents/_onlab_git/ami/audio-test-pyannote.rttm') as f :\n",
    "    hyp = Annotation.from_rttm(f)\n",
    "\n",
    "#ref = '/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm'\n",
    "#hyp = '/home/kozi/Documents/_onlab_git/ami/audio-test-pyannote.rttm'\n",
    "der = DiarizationErrorRate()                                                                                          \n",
    "der_result = der(ref, hyp)                                                                                                                    \n",
    "print(f'DER: {der_result:.2f}')         \n",
    "\n",
    "der = DiarizationErrorRate()\n",
    "\n",
    "der_result = der(ref,hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading speaker turns from reference RTTMs...\n",
      "Loading speaker turns from system RTTMs...\n",
      "WARNING: No universal evaluation map specified. Approximating from reference and speaker turn extents...\n",
      "Trimming reference speaker turns to UEM scoring regions...\n",
      "Trimming system speaker turns to UEM scoring regions...\n",
      "Checking for overlapping reference speaker turns...\n",
      "Checking for overlapping system speaker turns...\n",
      "Scoring...\n",
      "WARNING: File \"EN2002a\" missing in system RTTMs.\n",
      "WARNING: File \"EN2002a.Array1-01\" missing in reference RTTMs.\n",
      "File                  DER     JER    B3-Precision    B3-Recall    B3-F1    GKT(ref, sys)    GKT(sys, ref)    H(ref|sys)    H(sys|ref)    MI    NMI\n",
      "-----------------  ------  ------  --------------  -----------  -------  ---------------  ---------------  ------------  ------------  ----  -----\n",
      "EN2002a              0.00  100.00            0.14         1.00     0.24             1.00             0.00          3.26          0.00  0.00   0.00\n",
      "EN2002a.Array1-01  100.00  100.00            1.00         0.24     0.38             0.00             1.00          0.00          2.60  0.00   0.00\n",
      "*** OVERALL ***      0.00  100.00            0.57         0.62     0.59             0.45             0.40          1.63          1.30  1.00   0.41\n"
     ]
    }
   ],
   "source": [
    "!python3 /home/kozi/Documents/_onlab_git/dscore/score.py -s '/home/kozi/Documents/_onlab_git/ami/audio-test-pyannote.rttm' -r \"/home/kozi/Documents/_onlab_git/ami/ami_dataset/test/rttm/EN2002a.rttm\" # system outputs and reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... 100% is unlikely (NeMo is supposed to overperform pyannote)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
