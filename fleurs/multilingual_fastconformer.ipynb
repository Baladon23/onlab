{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to traverse the Fleurs dataset\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def traverse_fleurs(fun, model=\"\", input_manifest_name=\"\", output_manifest_name=\"\", skip_Hungarian=False):\n",
    "    fleurs_dataset_dirs = [\"be_by\", \"de_de\", \"en_us\", \"fr_fr\", \"gl_es\", \"hr_hr\", \"hu_hu\", \"it_it\", \"pl_pl\", \"ru_ru\", \"uk_ua\"]\n",
    "\n",
    "    for subdir_string in fleurs_dataset_dirs:\n",
    "        if skip_Hungarian and subdir_string == \"hu_hu\":\n",
    "            continue\n",
    "\n",
    "        subdir = os.path.join(\"/home/kozi/Documents/fleurs\", subdir_string)\n",
    "        input_manifest = os.path.join(subdir, input_manifest_name)\n",
    "        if input_manifest_name == \"\" or not os.path.isfile(input_manifest):\n",
    "            print(\"Manifest not found: \" + input_manifest)\n",
    "            continue\n",
    "\n",
    "        fun(model, subdir, input_manifest, output_manifest_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert fastconformer output to UTF-8\n",
    "\n",
    "import json                                                                 \n",
    "import os                     \n",
    "                                                                                                \n",
    "def convert_unicode_to_text(unicode_data):                                                       \n",
    "    data = json.loads(unicode_data)                                                              \n",
    "    converted_data = json.dumps(data, ensure_ascii=False)                                        \n",
    "    return converted_data                                                                        \n",
    "                                                                                                \n",
    "def convert_line_by_line(model, subdir, input_manifest, output_manifest):       \n",
    "    outfile = os.path.join(subdir, output_manifest)                                         \n",
    "    with open(input_manifest, 'r', encoding='utf-8') as infile, open(outfile, 'w', encoding='utf-8') as outfile:                                                                    \n",
    "        for line in infile:                                                                            \n",
    "            converted_line = convert_unicode_to_text(line)                                           \n",
    "            outfile.write(converted_line + \"\\n\")\n",
    "\n",
    "traverse_fleurs(convert_line_by_line, \"\", \"fastconformer_capitalized_output.json\", \"fastconformer_capitalized_output_utf8.json\", skip_Hungarian=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to rename files, not necessary\n",
    "def rename_outputs(model, subdir, input_manifest, output_manifest):\n",
    "    os.rename(os.path.join(subdir, input_manifest), os.path.join(subdir, output_manifest))\n",
    "\n",
    "#traverse_fleurs(rename_outputs, \"subdir\", \"fastconformer_capitalized_output.json\", \"fastconformer_capitalized_output_utf8.json\", skip_Hungarian=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:22:11 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:22:11 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/be_by/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/be_by/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:22:11 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:22:12 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:22:15 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:22:19 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:22:19 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:22:19 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:22:19 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:22:20 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:22:20 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:22:20 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:22:22 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:22:23 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:22:23 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:22:23 transcribe_utils:235] \n",
      "    Transcribing 967 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 967/967 [03:45<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:26:08 transcribe_speech:349] Finished transcribing 967 files !\n",
      "[NeMo I 2023-10-22 16:26:08 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/be_by/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:26:08 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/be_by/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:26:08 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/be_by/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:26:08 transcribe_speech:381] {'samples': 967, 'tokens': 20582, 'wer': 0.20726848702749975, 'ins_rate': 0.024778933048294625, 'del_rate': 0.01579049655038383, 'sub_rate': 0.1666990574288213}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:26:15 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:26:15 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/de_de/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/de_de/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:26:15 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:26:16 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:26:20 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:26:23 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:26:23 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:26:23 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:26:23 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:26:24 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:26:25 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:26:25 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:26:27 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:26:27 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:26:27 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:26:27 transcribe_utils:235] \n",
      "    Transcribing 862 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 862/862 [03:03<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:29:30 transcribe_speech:349] Finished transcribing 862 files !\n",
      "[NeMo I 2023-10-22 16:29:30 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/de_de/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:29:30 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/de_de/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:29:30 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/de_de/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:29:30 transcribe_speech:381] {'samples': 862, 'tokens': 18516, 'wer': 0.12389284942752214, 'ins_rate': 0.012205659969755887, 'del_rate': 0.0073449989198531, 'sub_rate': 0.10434219053791316}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:29:37 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:29:37 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/en_us/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/en_us/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:29:37 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:29:38 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:29:42 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:29:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:29:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:29:45 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:29:45 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:29:46 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:29:47 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:29:47 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:29:49 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:29:49 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:29:49 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:29:49 transcribe_utils:235] \n",
      "    Transcribing 647 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 647/647 [01:51<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:31:41 transcribe_speech:349] Finished transcribing 647 files !\n",
      "[NeMo I 2023-10-22 16:31:41 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/en_us/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:31:41 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/en_us/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:31:41 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/en_us/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:31:41 transcribe_speech:381] {'samples': 647, 'tokens': 14352, 'wer': 0.1690356744704571, 'ins_rate': 0.025431995540691192, 'del_rate': 0.009894091415830546, 'sub_rate': 0.13370958751393533}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:31:48 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:31:48 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/fr_fr/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/fr_fr/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:31:48 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:31:49 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:31:52 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:31:55 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:31:55 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:31:55 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:31:55 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:31:56 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:31:57 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:31:57 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:31:59 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:31:59 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:31:59 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:31:59 transcribe_utils:235] \n",
      "    Transcribing 676 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 676/676 [02:04<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:34:04 transcribe_speech:349] Finished transcribing 676 files !\n",
      "[NeMo I 2023-10-22 16:34:04 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/fr_fr/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:34:04 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/fr_fr/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:34:04 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/fr_fr/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:34:04 transcribe_speech:381] {'samples': 676, 'tokens': 17119, 'wer': 0.19142473275308136, 'ins_rate': 0.038553653834920265, 'del_rate': 0.01682341258251066, 'sub_rate': 0.13604766633565044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:34:10 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:34:11 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/gl_es/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/gl_es/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:34:11 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:34:12 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:34:15 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:34:18 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:34:18 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:34:18 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:34:18 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:34:19 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:34:20 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:34:20 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:34:22 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:34:22 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:34:22 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:34:22 transcribe_utils:235] \n",
      "    Transcribing 927 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 927/927 [02:31<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:36:53 transcribe_speech:349] Finished transcribing 927 files !\n",
      "[NeMo I 2023-10-22 16:36:53 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/gl_es/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:36:53 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/gl_es/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:36:53 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/gl_es/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:36:53 transcribe_speech:381] {'samples': 927, 'tokens': 22134, 'wer': 0.5638384386012469, 'ins_rate': 0.037498870515948315, 'del_rate': 0.06198608475648324, 'sub_rate': 0.4643534833288154}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:37:00 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:37:00 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/hr_hr/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/hr_hr/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:37:00 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:37:01 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:37:04 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:37:07 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:37:07 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:37:07 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:37:07 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:37:08 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:37:09 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:37:09 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:37:11 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:37:11 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:37:11 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:37:11 transcribe_utils:235] \n",
      "    Transcribing 914 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 914/914 [02:33<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:39:45 transcribe_speech:349] Finished transcribing 914 files !\n",
      "[NeMo I 2023-10-22 16:39:45 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/hr_hr/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:39:45 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/hr_hr/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:39:45 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/hr_hr/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:39:45 transcribe_speech:381] {'samples': 914, 'tokens': 17675, 'wer': 0.8748514851485149, 'ins_rate': 0.010636492220650636, 'del_rate': 0.11077793493635078, 'sub_rate': 0.7534370579915134}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:39:52 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:39:52 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/it_it/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/it_it/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:39:52 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:39:53 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:39:57 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:40:00 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:40:00 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:40:00 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:40:00 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:40:01 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:40:01 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:40:01 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:40:04 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:40:04 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:40:04 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:40:04 transcribe_utils:235] \n",
      "    Transcribing 865 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 865/865 [03:10<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:43:14 transcribe_speech:349] Finished transcribing 865 files !\n",
      "[NeMo I 2023-10-22 16:43:14 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/it_it/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:43:14 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/it_it/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:43:14 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/it_it/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:43:14 transcribe_speech:381] {'samples': 865, 'tokens': 20605, 'wer': 0.14098519776753216, 'ins_rate': 0.0115505945158942, 'del_rate': 0.010822615869934481, 'sub_rate': 0.11861198738170348}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:43:21 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:43:21 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/pl_pl/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/pl_pl/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:43:21 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:43:22 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:43:25 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:43:29 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:43:29 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:43:29 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:43:29 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:43:30 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:43:30 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:43:30 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:43:32 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:43:33 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:43:33 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:43:33 transcribe_utils:235] \n",
      "    Transcribing 758 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 758/758 [02:11<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:45:44 transcribe_speech:349] Finished transcribing 758 files !\n",
      "[NeMo I 2023-10-22 16:45:44 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/pl_pl/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:45:44 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/pl_pl/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:45:44 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/pl_pl/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:45:44 transcribe_speech:381] {'samples': 758, 'tokens': 14332, 'wer': 0.19990231649455764, 'ins_rate': 0.020722857940273513, 'del_rate': 0.014582751883896176, 'sub_rate': 0.16459670667038795}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:45:51 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:45:51 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/ru_ru/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/ru_ru/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:45:51 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:45:52 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:45:56 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:45:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:45:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:45:59 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:45:59 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:46:00 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:46:01 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:46:01 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:46:03 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:46:03 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:46:03 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:46:03 transcribe_utils:235] \n",
      "    Transcribing 775 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 775/775 [02:47<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:48:51 transcribe_speech:349] Finished transcribing 775 files !\n",
      "[NeMo I 2023-10-22 16:48:51 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/ru_ru/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:48:51 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/ru_ru/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:48:51 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/ru_ru/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:48:51 transcribe_speech:381] {'samples': 775, 'tokens': 15039, 'wer': 0.1804641266041625, 'ins_rate': 0.024270230733426424, 'del_rate': 0.013963694394574106, 'sub_rate': 0.14223020147616197}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:48:58 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:48:58 transcribe_speech:181] Hydra config: model_path: /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\n",
      "    pretrained_name: null\n",
      "    audio_dir: null\n",
      "    dataset_manifest: /home/kozi/Documents/fleurs/uk_ua/whisper_manifest.json\n",
      "    channel_selector: null\n",
      "    audio_key: audio_filepath\n",
      "    eval_config_yaml: null\n",
      "    output_filename: /home/kozi/Documents/fleurs/uk_ua/fastconformer_capitalized_output.json\n",
      "    batch_size: 1\n",
      "    num_workers: 0\n",
      "    append_pred: false\n",
      "    pred_name_postfix: null\n",
      "    random_seed: null\n",
      "    compute_timestamps: false\n",
      "    preserve_alignment: false\n",
      "    compute_langs: false\n",
      "    cuda: null\n",
      "    allow_mps: false\n",
      "    amp: false\n",
      "    amp_dtype: float16\n",
      "    audio_type: wav\n",
      "    overwrite_transcripts: true\n",
      "    ctc_decoding:\n",
      "      strategy: greedy\n",
      "      preserve_alignments: null\n",
      "      compute_timestamps: null\n",
      "      word_seperator: ' '\n",
      "      ctc_timestamp_type: all\n",
      "      batch_dim_index: 0\n",
      "      greedy:\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        preserve_alignments: false\n",
      "        compute_timestamps: false\n",
      "        return_best_hypothesis: true\n",
      "        beam_alpha: 1.0\n",
      "        beam_beta: 0.0\n",
      "        kenlm_path: null\n",
      "        flashlight_cfg:\n",
      "          lexicon_path: null\n",
      "          boost_path: null\n",
      "          beam_size_token: 16\n",
      "          beam_threshold: 20.0\n",
      "          unk_weight: -.inf\n",
      "          sil_weight: 0.0\n",
      "        pyctcdecode_cfg:\n",
      "          beam_prune_logp: -10.0\n",
      "          token_min_logp: -5.0\n",
      "          prune_history: false\n",
      "          hotwords: null\n",
      "          hotword_weight: 10.0\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      temperature: 1.0\n",
      "    rnnt_decoding:\n",
      "      model_type: rnnt\n",
      "      strategy: greedy_batch\n",
      "      compute_hypothesis_token_set: false\n",
      "      preserve_alignments: null\n",
      "      confidence_cfg:\n",
      "        preserve_frame_confidence: false\n",
      "        preserve_token_confidence: false\n",
      "        preserve_word_confidence: false\n",
      "        exclude_blank: true\n",
      "        aggregation: min\n",
      "        method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      fused_batch_size: -1\n",
      "      compute_timestamps: null\n",
      "      compute_langs: false\n",
      "      word_seperator: ' '\n",
      "      rnnt_timestamp_type: all\n",
      "      greedy:\n",
      "        max_symbols_per_step: 10\n",
      "        preserve_alignments: false\n",
      "        preserve_frame_confidence: false\n",
      "        confidence_method_cfg:\n",
      "          name: entropy\n",
      "          entropy_type: tsallis\n",
      "          alpha: 0.33\n",
      "          entropy_norm: exp\n",
      "          temperature: DEPRECATED\n",
      "      beam:\n",
      "        beam_size: 4\n",
      "        search_type: default\n",
      "        score_norm: true\n",
      "        return_best_hypothesis: true\n",
      "        tsd_max_sym_exp_per_step: 50\n",
      "        alsd_max_target_len: 1.0\n",
      "        nsc_max_timesteps_expansion: 1\n",
      "        nsc_prefix_alpha: 1\n",
      "        maes_num_steps: 2\n",
      "        maes_prefix_alpha: 1\n",
      "        maes_expansion_gamma: 2.3\n",
      "        maes_expansion_beta: 2\n",
      "        language_model: null\n",
      "        softmax_temperature: 1.0\n",
      "        preserve_alignments: false\n",
      "        ngram_lm_model: null\n",
      "        ngram_lm_alpha: 0.0\n",
      "        hat_subtract_ilm: false\n",
      "        hat_ilm_weight: 0.0\n",
      "      temperature: 1.0\n",
      "    decoder_type: null\n",
      "    att_context_size: null\n",
      "    model_change:\n",
      "      conformer:\n",
      "        self_attention_model: null\n",
      "        att_context_size: null\n",
      "    calculate_wer: true\n",
      "    clean_groundtruth_text: false\n",
      "    langid: en\n",
      "    use_cer: false\n",
      "    return_transcriptions: false\n",
      "    return_hypotheses: true\n",
      "    \n",
      "[NeMo I 2023-10-22 16:48:58 transcribe_speech:227] Inference will be done on device: cuda:0\n",
      "[NeMo I 2023-10-22 16:48:59 transcribe_utils:188] Restoring model : EncDecHybridRNNTCTCBPEModel\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:194] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 mixins:322] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
      "[NeMo I 2023-10-22 16:49:03 aggregate_tokenizer:72] Aggregate vocab size: 2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:49:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    concat_samples: false\n",
      "    concat_samples_count_as_one: true\n",
      "    concat_samles_max_length: 22\n",
      "    concat_samples_min_langth: 16\n",
      "    concat_samples_joining_pause: 0.1\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/by/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ru/v2/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/ua/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..127_CL_.json\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/it/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/de/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/hr/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/fr/new/tar_dataset_train/sharded_manifests_pcstrp/manifest__OP_0..511_CL_.json\n",
      "    - - /data/mml/pl/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/by/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/es/nemo_sp_asr_set_3pt0/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ru/v2/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/ua/tarred_train/audio__OP_0..127_CL_.tar\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/it/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/de/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/hr/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/fr/new/tar_dataset_train/audio__OP_0..511_CL_.tar\n",
      "    - - /data/mml/pl/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.082987552\n",
      "    - 0.057883817\n",
      "    - 0.165975104\n",
      "    - 0.182987552\n",
      "    - 0.248962656\n",
      "    - 0.041493776\n",
      "    - 0.107883817\n",
      "    - 0.020746888\n",
      "    - 0.057883817\n",
      "    - 0.033195021\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 2.0\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2023-10-22 16:49:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: ml_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.01038203461\n",
      "      - 0.02906918126\n",
      "      - 0.05578404896\n",
      "      - 0.00793393209\n",
      "      - 0.03529332571\n",
      "      - 0.06676942709\n",
      "      - 0.008910626092\n",
      "      - 0.04183922745\n",
      "      - 0.03702357048\n",
      "      - 0.01187105446\n",
      "      - 0.08992238524\n",
      "      - 0.07811239919\n",
      "      - 0.1053836677\n",
      "      - 0.04190414069\n",
      "      - 0.05478461376\n",
      "      - 0.009764405572\n",
      "      - 0.015433846\n",
      "      - 0.002319494\n",
      "      - 0.007748472\n",
      "      - 0.068500786\n",
      "      - 0.012861959\n",
      "      - 0.02184065518\n",
      "      - 0.02110108024\n",
      "      - 0.0360362326\n",
      "      - 0.01150828872\n",
      "      - 0.01506389296\n",
      "      - 0.01318416012\n",
      "      - 0.02223965921\n",
      "      - 0.0208300262\n",
      "      - 0.0119929005\n",
      "      - 0.005325489979\n",
      "      - 0.02926501627\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "        - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "        - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "        - /data/mml/by/dev_pcstrip_by.json\n",
      "        - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "        - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "        - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "        - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "        - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: es_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.1006311469\n",
      "      - 0.2817622132\n",
      "      - 0.5407044993\n",
      "      - 0.07690214062\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/es/nemo_sp_asr_set_3pt0/dev/fisher/dev_fisher_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mcv12/dev_mcv12_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/mls/dev_mls_manifest_pcstrip_es.json\n",
      "        - /data/mml/es/nemo_sp_asr_set_3pt0/dev/voxpopuli/dev_voxpopuli_manifest_pcstrip_es.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: de_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3180341634\n",
      "      - 0.6016706687\n",
      "      - 0.08029516792\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/de/dev_mcv12_pcstrip_de.json\n",
      "        - /data/mml/de/dev_mls_pcstrip_de.json\n",
      "        - /data/mml/de/dev_voxpopuli_pcstrip_de.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: it_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.4611203685\n",
      "      - 0.4080458341\n",
      "      - 0.1308337974\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/it/dev/mcv/dev_it_mcv_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/mls/dev_it_mls_manifest_pcstrip_it.json\n",
      "        - /data/mml/it/dev/voxpopuli/dev_it_voxpopuli_manifest_pcstrip_it.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: by_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/by/dev_pcstrip_by.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ua_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/ua/test_manifest_pcstrip_ua.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: hr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 1\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/hr/devtest/dev_pcstrip_hr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: fr_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.3936392371\n",
      "      - 0.5146358619\n",
      "      - 0.09172490108\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/fr/new/dataset_dev_MCV12/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_MLS/dev_pcstrp_fr.json\n",
      "        - /data/mml/fr/new/dataset_dev_VoxPopuli/dev_pcstrp_fr.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: ru_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.5\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.144424369\n",
      "      - 0.021704987\n",
      "      - 0.07250741\n",
      "      - 0.641005657\n",
      "      - 0.120357577\n",
      "      manifest_filepath:\n",
      "      - /data/mml/ru/v2/eval_data/sova_RuAudiobooksDevices/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/mcv12/dev_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_farfield_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/golos/test_crowd_PC_pcstrip_ru.json\n",
      "      - /data/mml/ru/v2/eval_data/dusha/test_PC_pcstrip_ru.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    - name: pl_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 1\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.276541113\n",
      "      - 0.2671767933\n",
      "      - 0.4562820937\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/pl/mcv-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/mls-dev_pcstrip_pl.json\n",
      "        - /data/mml/pl/voxpopuli-dev_pcstrip_pl.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 8\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 2.0\n",
      "      use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-10-22 16:49:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:49:06 features:289] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-22 16:49:07 nemo_logging:349] /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:49:08 rnnt_models:211] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2023-10-22 16:49:08 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-10-22 16:49:10 save_restore_connector:249] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2023-10-22 16:49:10 rnnt_wer:676] Joint fused batch size <= 0; Will temporarily disable fused batch step in the Joint.\n",
      "[NeMo I 2023-10-22 16:49:10 hybrid_rnnt_ctc_bpe_models:424] Changed decoding strategy of the RNNT decoder to \n",
      "    model_type: rnnt\n",
      "    strategy: greedy_batch\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: false\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    fused_batch_size: -1\n",
      "    compute_timestamps: false\n",
      "    compute_langs: false\n",
      "    word_seperator: ' '\n",
      "    rnnt_timestamp_type: all\n",
      "    greedy:\n",
      "      max_symbols_per_step: 10\n",
      "      preserve_alignments: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      score_norm: true\n",
      "      return_best_hypothesis: true\n",
      "      tsd_max_sym_exp_per_step: 50\n",
      "      alsd_max_target_len: 1.0\n",
      "      nsc_max_timesteps_expansion: 1\n",
      "      nsc_prefix_alpha: 1\n",
      "      maes_num_steps: 2\n",
      "      maes_prefix_alpha: 1\n",
      "      maes_expansion_gamma: 2.3\n",
      "      maes_expansion_beta: 2\n",
      "      language_model: null\n",
      "      softmax_temperature: 1.0\n",
      "      preserve_alignments: false\n",
      "      ngram_lm_model: null\n",
      "      ngram_lm_alpha: 0.0\n",
      "      hat_subtract_ilm: false\n",
      "      hat_ilm_weight: 0.0\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2023-10-22 16:49:10 transcribe_utils:235] \n",
      "    Transcribing 750 files...\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Transcribing: 100%|██████████| 750/750 [02:32<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-22 16:51:43 transcribe_speech:349] Finished transcribing 750 files !\n",
      "[NeMo I 2023-10-22 16:51:43 transcribe_speech:350] Writing transcriptions into file: /home/kozi/Documents/fleurs/uk_ua/fastconformer_capitalized_output.json\n",
      "[NeMo I 2023-10-22 16:51:43 transcribe_speech:368] Finished writing predictions to /home/kozi/Documents/fleurs/uk_ua/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:51:43 transcribe_speech:380] Writing prediction and error rate of each sample to /home/kozi/Documents/fleurs/uk_ua/fastconformer_capitalized_output.json!\n",
      "[NeMo I 2023-10-22 16:51:43 transcribe_speech:381] {'samples': 750, 'tokens': 14240, 'wer': 0.20814606741573033, 'ins_rate': 0.02282303370786517, 'del_rate': 0.01720505617977528, 'sub_rate': 0.16811797752808988}\n"
     ]
    }
   ],
   "source": [
    "# without batch_size=1 the script fails for be_by, de_de and it_it (it skips hu_hu) languages, so it needs to be ran manually for these languages for higher (than 1??) batch sizes\n",
    "# completes in 30 minutes\n",
    "import os\n",
    "\n",
    "\n",
    "fleurs_dataset_dirs = [\"be_by\", \"de_de\", \"en_us\", \"fr_fr\", \"gl_es\", \"hr_hr\", \"hu_hu\", \"it_it\", \"pl_pl\", \"ru_ru\", \"uk_ua\"]\n",
    "\n",
    "for subdir_string in fleurs_dataset_dirs:\n",
    "    if subdir_string == \"hu_hu\":\n",
    "        continue\n",
    "\n",
    "    subdir = os.path.join(\"/home/kozi/Documents/fleurs\", subdir_string)\n",
    "    manifest = os.path.join(subdir, \"whisper_manifest.json\")\n",
    "    if not os.path.isfile(manifest):\n",
    "        print(\"Manifest not found: \" + manifest)\n",
    "        continue\n",
    "    \n",
    "    script_path = \"/home/kozi/Documents/NeMo/examples/asr/transcribe_speech.py\"\n",
    "    # ref. https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_multilingual_fastconformer_hybrid_large_pc\n",
    "    model_path = \"/home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo\"\n",
    "    output_filename = os.path.join(subdir, \"fastconformer_capitalized_output.json\")\n",
    "\n",
    "    os.system(\"python3 {} model_path={} dataset_manifest={} output_filename={} use_cer=False batch_size=1\".format(script_path, model_path, manifest, output_filename))\n",
    "\n",
    "#!python3 /home/kozi/Documents/NeMo/examples/asr/transcribe_speech.py \\\n",
    "#    model_path=/home/kozi/Documents/stt_multilingual_fastconformer_hybrid_large_pc.nemo \\\n",
    "#    dataset_manifest=/home/kozi/Documents/fleurs/be_by/whisper_manifest.json  \\\n",
    "#    output_filename=/home/kozi/Documents/fleurs/be_by/fastconformer_output_be_by.json use_cer=False batch_size=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
