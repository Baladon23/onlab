{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein # ref. https://pypi.org/project/Levenshtein/\n",
    "import editdistance # ref. https://pypi.org/project/editdistance/\n",
    "from jiwer import wer, cer # ref. https://jitsi.github.io/jiwer/usage/\n",
    "\n",
    "#actual distances, not rates\n",
    "print(Levenshtein.distance(\"foo\", \"foobar\"))\n",
    "print(editdistance.eval(\"foo\", \"foobar\"))\n",
    "\n",
    "# sentences\n",
    "reference = [\"hello world\", \"i like monthy python\"]\n",
    "\n",
    "hypothesis = [\"hello duck\", \"i like python\"]\n",
    "#error RATE, not #bad_words\n",
    "error = wer(reference, hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the AMI dataset\n",
    "# ref. https://huggingface.co/datasets/edinburghcstr/ami#supported-tasks-and-leaderboards\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 'independent headset microphone' and 'single distant microphone'\n",
    "ds = load_dataset(\"edinburghcstr/ami\", \"ihm\") #\"sdm\"\n",
    "# output: /home/kozi/.cache/huggingface/datasets/downloads/extracted/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_id': 'EN2001a',\n",
       " 'audio_id': 'AMI_EN2001a_H04_MEO069_0330297_0330718',\n",
       " 'text': 'IF YOU IF YOU S. S. H. AND THEY HAVE THIS BIG WARNING ABOUT DOING NOTHING AT ALL IN THE GATEWAY MACHINE',\n",
       " 'audio': {'path': '/home/kozi/.cache/huggingface/datasets/downloads/extracted/30f379de5d63bf3da87f6320b8c18dad7a58e3c1bd2ef6e0c9a55c3d1d64567d/EN2001a/train_ami_en2001a_h04_meo069_0330297_0330718.wav',\n",
       "  'array': array([ 0.00231934, -0.00183105, -0.00543213, ..., -0.00238037,\n",
       "         -0.00244141, -0.00219727]),\n",
       "  'sampling_rate': 16000},\n",
       " 'begin_time': 3302.969970703125,\n",
       " 'end_time': 3307.179931640625,\n",
       " 'microphone_id': 'H04',\n",
       " 'speaker_id': 'MEO069'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Model titanet_large was not found. Check cls.list_available_models() for the list of all available models.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnemo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnemo_asr\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from nemo.collections.asr.models.label_models import ExtractSpeakerEmbeddingsModel\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                                                                                   \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load pre-trained speaker embeddings model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mnemo_asr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecDiarLabelModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitanet_large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                                                                                   \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Set paths to audio files and other configurations                                                                                      \u001b[39;00m\n\u001b[1;32m     10\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/your/audio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/core/classes/common.py:848\u001b[0m, in \u001b[0;36mModel.from_pretrained\u001b[0;34m(cls, model_name, refresh_cache, override_config_path, map_location, strict, return_config, trainer, save_restore_connector)\u001b[0m\n\u001b[1;32m    843\u001b[0m     class_, nemo_model_file_in_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hf_hub_pretrained_model_info(\n\u001b[1;32m    844\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name, refresh_cache\u001b[38;5;241m=\u001b[39mrefresh_cache\n\u001b[1;32m    845\u001b[0m     )\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# NGC source\u001b[39;00m\n\u001b[0;32m--> 848\u001b[0m     class_, nemo_model_file_in_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ngc_pretrained_model_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_cache\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m instance \u001b[38;5;241m=\u001b[39m class_\u001b[38;5;241m.\u001b[39mrestore_from(\n\u001b[1;32m    853\u001b[0m     restore_path\u001b[38;5;241m=\u001b[39mnemo_model_file_in_cache,\n\u001b[1;32m    854\u001b[0m     override_config_path\u001b[38;5;241m=\u001b[39moverride_config_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m     save_restore_connector\u001b[38;5;241m=\u001b[39msave_restore_connector,\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
      "File \u001b[0;32m~/Documents/NeMo/nemo/core/classes/common.py:900\u001b[0m, in \u001b[0;36mModel._get_ngc_pretrained_model_info\u001b[0;34m(cls, model_name, refresh_cache)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location_in_the_cloud \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was not found. Check cls.list_available_models() for the list of all available models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m     )\n\u001b[1;32m    903\u001b[0m filename \u001b[38;5;241m=\u001b[39m location_in_the_cloud\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    904\u001b[0m url \u001b[38;5;241m=\u001b[39m location_in_the_cloud\u001b[38;5;241m.\u001b[39mreplace(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Model titanet_large was not found. Check cls.list_available_models() for the list of all available models."
     ]
    }
   ],
   "source": [
    "import os     \n",
    "import nemo.collections.asr as nemo_asr \n",
    "#from nemo.collections.asr.models.label_models import ExtractSpeakerEmbeddingsModel\n",
    "                                                                                  \n",
    "# Load pre-trained speaker embeddings model\n",
    "#model = nemo_asr.models.EncDecDiarLabelModel.from_pretrained(model_name=\"titanet_large\")\n",
    "model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
    "                                                                                  \n",
    "# Set paths to audio files and other configurations                                                                                      \n",
    "audio_file = \"path/to/your/audio.wav\"\n",
    "                                                                                                                                                                       \n",
    "# Extract embeddings  \n",
    "embeddings = model.get_embeddings(audio_file)        \n",
    "print(embeddings)              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
