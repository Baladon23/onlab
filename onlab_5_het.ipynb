{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "                         /home/kozi/Downloads/oobabooga_linux/installer_files/conda\n",
      "                         /home/kozi/Downloads/oobabooga_linux/installer_files/env\n",
      "base                     /home/kozi/anaconda3\n",
      "nemo                     /home/kozi/anaconda3/envs/nemo\n",
      "nemo2                 *  /home/kozi/anaconda3/envs/nemo2\n",
      "\n",
      "Requirement already satisfied: transformers in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: soundfile in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/kozi/anaconda3/envs/nemo2/lib/python3.8/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!conda env list\n",
    "#%pip install transformers                                                      \n",
    "#%pip install soundfile   \n",
    "#%pip install openai-whisper tqdm faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NeMo models\n",
    "\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import os\n",
    "                                   \n",
    "\n",
    "print(\"started loading models\")\n",
    "#quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
    "asr_models = []\n",
    "asr_models.append(nemo_asr.models.EncDecCTCModelBPE.restore_from(\"/home/kozi/Documents/stt_en_conformer_ctc_small.nemo\")) #from_pretrained() vs restore_from()\n",
    "asr_models.append(nemo_asr.models.EncDecCTCModelBPE.restore_from(\"/home/kozi/Documents/stt_en_conformer_ctc_large.nemo\"))\n",
    "print(\"finished loading models\")\n",
    "\n",
    "# source of models https://huggingface.co/models?library=nemo&sort=trending&search=nvidia%2Fstt_en_conformer or https://huggingface.co/nvidia/stt_en_conformer_ctc_small/tree/main\n",
    "# or even https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/models.html\n",
    "\n",
    "#files = [os.path.join(data_dir, 'an4/wav/an4_clstk/mgah/cen2-mgah-b.wav')]\n",
    "#for fname, transcription in zip(files, quartznet.transcribe(paths2audio_files=files)):\n",
    "  #print(f\"Audio in {fname} was recognized as: {transcription}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcribe with previously loaded models\n",
    "\n",
    "def transcribe_files(dir):\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            full_file_path = os.path.join(root, file)\n",
    "\n",
    "            if file.endswith('.txt'):\n",
    "                with open(full_file_path, 'r') as f:\n",
    "                    for line in f.readlines():\n",
    "                        print(line)\n",
    "            if file.endswith('.flac'):\n",
    "                for model in asr_models: \n",
    "                    transcribed = model.transcribe([full_file_path])\n",
    "                    print(file, transcribed)\n",
    "\n",
    "transcribe_files(\"/home/kozi/Documents/librispeech/test_other/test-other/367/130732/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4 generated code to run facebook wav2vec models, not necessary\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    \n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "# tokenize\n",
    "input_values = processor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "\n",
    "# retrieve logits\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a subset of FLEURS if necessary\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#_FLEURS_LANG = sorted([\"af_za\", \"am_et\", \"ar_eg\", \"as_in\", \"ast_es\", \"az_az\", \"be_by\", \"bn_in\", \"bs_ba\", \"ca_es\", \"ceb_ph\", \"cmn_hans_cn\", \"yue_hant_hk\", \"cs_cz\", \"cy_gb\", \"da_dk\", \"de_de\", \"el_gr\", \"en_us\", \"es_419\", \"et_ee\", \"fa_ir\", \"ff_sn\", \"fi_fi\", \"fil_ph\", \"fr_fr\", \"ga_ie\", \"gl_es\", \"gu_in\", \"ha_ng\", \"he_il\", \"hi_in\", \"hr_hr\", \"hu_hu\", \"hy_am\", \"id_id\", \"ig_ng\", \"is_is\", \"it_it\", \"ja_jp\", \"jv_id\", \"ka_ge\", \"kam_ke\", \"kea_cv\", \"kk_kz\", \"km_kh\", \"kn_in\", \"ko_kr\", \"ckb_iq\", \"ky_kg\", \"lb_lu\", \"lg_ug\", \"ln_cd\", \"lo_la\", \"lt_lt\", \"luo_ke\", \"lv_lv\", \"mi_nz\", \"mk_mk\", \"ml_in\", \"mn_mn\", \"mr_in\", \"ms_my\", \"mt_mt\", \"my_mm\", \"nb_no\", \"ne_np\", \"nl_nl\", \"nso_za\", \"ny_mw\", \"oc_fr\", \"om_et\", \"or_in\", \"pa_in\", \"pl_pl\", \"ps_af\", \"pt_br\", \"ro_ro\", \"ru_ru\", \"bg_bg\", \"sd_in\", \"sk_sk\", \"sl_si\", \"sn_zw\", \"so_so\", \"sr_rs\", \"sv_se\", \"sw_ke\", \"ta_in\", \"te_in\", \"tg_tj\", \"th_th\", \"tr_tr\", \"uk_ua\", \"umb_ao\", \"ur_pk\", \"uz_uz\", \"vi_vn\", \"wo_sn\", \"xh_za\", \"yo_ng\", \"zu_za\"])\n",
    "# ref. https://huggingface.co/datasets/google/xtreme_s/blob/main/xtreme_s.py line 105\n",
    "\n",
    "fleurs_dataset_dirs = [\"be_by\", \"de_de\", \"en_us\", \"fr_fr\", \"gl_es\", \"hr_hr\", \"hu_hu\", \"it_it\", \"pl_pl\", \"ru_ru\", \"uk_ua\"]\n",
    "\n",
    "for ds_string in ['de_de', 'en_us', 'fr_fr', 'hu_hu', 'ru_ru']:\n",
    "    ds = load_dataset(\"google/xtreme_s\", \"fleurs.{}\".format(ds_string))\n",
    "    print(ds['train']['path'])\n",
    "\n",
    "# or downloaded_model = load_dataset(\"/home/kozi/Documents/fleurs/ds_string/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine a fleurs dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "de = load_dataset(\"/home/kozi/Documents/fleurs/en_us/\")\n",
    "de['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ... -3.15904617e-06\n",
      " -3.03983688e-06 -3.27825546e-06]\n",
      "/home/kozi/Documents/fleurs/en_us/audio/train/10004088536354799741.wav\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cb02a0c19041b1a6906944c517919a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['a tornado is a spinning column of very low pressure air which sues surrounding air inward and upward',\n",
       " 'i swear answered sancho']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test transcription with the fleurs dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(de['train'][0]['audio']['array'])\n",
    "print(de['train'][0]['audio']['path'])\n",
    "wav = de['train'][0]['audio']['path']\n",
    "flac = \"/home/kozi/Documents/librispeech/test_other/test-other/367/293981/367-293981-0000.flac\"\n",
    "#asr_models[0].transcribe([flac])\n",
    "asr_models[0].transcribe([wav, flac])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example workflow for notebooks\n",
    "# download librispeech dataset (please run from the terminal)\n",
    "#   ref.: https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/datasets.html\n",
    "#!python3 /home/kozi/Documents/NeMo/scripts/dataset_processing/get_librispeech_data.py --data_root=data --data_set=test_other\n",
    "\n",
    "\n",
    "# create manifest_json for the already downloaded FLEURS english test dataset:\n",
    "# python3 /home/kozi/Documents/fleurs/fleurs_to_nemo_manifest.py /home/kozi/Documents/fleurs/en_us\n",
    "# ... use whisper_test.ipynb (perhaps renamed since) to run whisper transcription for Fleurs ...\n",
    "# ... use show_wer_cer_results.ipynb (perhaps renamed since) to calculate WER and CER for the manifests ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
